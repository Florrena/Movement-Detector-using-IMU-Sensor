{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a23eec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      acc_x     acc_y     acc_z    gyro_x    gyro_y    gyro_z  label\n",
      "0  0.042693 -1.784441  0.336893  0.110804 -0.074376  0.102657      0\n",
      "1 -0.001908 -1.579855 -0.242369  0.052294 -0.038513  0.108854      0\n",
      "2 -0.023960 -1.397642 -0.722993 -0.008995 -0.023952  0.115826      0\n",
      "3 -0.056374 -1.257657 -1.130061 -0.031175 -0.010533  0.100920      0\n",
      "4 -0.247819 -1.177400 -1.608836  0.002271  0.025864  0.061671      0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('dataset/dataset.csv')\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "337a1336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped X shape: (254, 50, 6)\n",
      "Reshaped y shape: (254,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sequence_length = 50 \n",
    "features = ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z']\n",
    "\n",
    "X = df[features].values \n",
    "y = df['label'].values\n",
    "\n",
    "\n",
    "num_full_windows = X.shape[0] // sequence_length\n",
    "trimmed_X = X[:num_full_windows * sequence_length]\n",
    "\n",
    "X_reshaped = trimmed_X.reshape(num_full_windows, sequence_length, 6)\n",
    "y_reshaped = y[sequence_length - 1::sequence_length] \n",
    "\n",
    "print(f\"Reshaped X shape: {X_reshaped.shape}\")\n",
    "print(f\"Reshaped y shape: {y_reshaped.shape}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a217b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized accelerometer data (acc_x, acc_y, acc_z): (np.float64(-395.0247963938985), np.float64(537.1252566475667))\n"
     ]
    }
   ],
   "source": [
    "X_reshaped[:, :, 0:3] *= 9.81  # Normalize acc_x, acc_y, acc_z to m/s2\n",
    "\n",
    "print(f\"Normalized accelerometer data (acc_x, acc_y, acc_z): {X_reshaped[:, :, 0:3].min(), X_reshaped[:, :, 0:3].max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50e50c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X = X_reshaped # shape (samples, 50, 6)\n",
    "y = y_reshaped # shape (samples,)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "np.save(\"X_train.npy\", X_train)\n",
    "np.save(\"y_train.npy\", y_train)\n",
    "np.save(\"X_val.npy\", X_val)\n",
    "np.save(\"y_val.npy\", y_val)\n",
    "np.save(\"X_test.npy\", X_test)\n",
    "np.save(\"y_test.npy\", y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "154fa77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Counter({np.int64(1): 51, np.int64(3): 51, np.int64(2): 51, np.int64(0): 50})\n",
      "Val: Counter({np.int64(0): 7, np.int64(3): 6, np.int64(2): 6, np.int64(1): 6})\n",
      "Test: Counter({np.int64(2): 7, np.int64(3): 7, np.int64(0): 6, np.int64(1): 6})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(\"Train:\", Counter(y_train))\n",
    "print(\"Val:\", Counter(y_val))\n",
    "print(\"Test:\", Counter(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5599710b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# Function to add random noise to the data\n",
    "def add_noise(data, noise_factor=0.01):\n",
    "    noise = np.random.normal(0, noise_factor, data.shape)\n",
    "    return data + noise\n",
    "\n",
    "def time_warp(data, target_length, sampling_rate=60, warp_factor=0.2):\n",
    "    random_warp = random.uniform(1 - warp_factor, 1 + warp_factor)\n",
    "    num_points = data.shape[0]\n",
    "    new_num_points = int(num_points * random_warp)\n",
    "    new_num_points = min(max(new_num_points, 1), target_length)\n",
    "\n",
    "    time_indices = np.linspace(0, num_points - 1, num_points)\n",
    "    new_time_indices = np.linspace(0, num_points - 1, new_num_points)\n",
    "    \n",
    "    interpolator = interp1d(time_indices, data, axis=0, kind='linear', fill_value=\"extrapolate\")\n",
    "    warped_data = interpolator(new_time_indices)\n",
    "\n",
    "    if warped_data.shape[0] < target_length:\n",
    "        pad_size = target_length - warped_data.shape[0]\n",
    "        warped_data = np.pad(warped_data, ((0, pad_size), (0, 0)), mode='constant', constant_values=0)\n",
    "    elif warped_data.shape[0] > target_length:\n",
    "        warped_data = warped_data[:target_length]\n",
    "    \n",
    "    return warped_data\n",
    "\n",
    "def jitter_data(data, jitter_factor=0.01):\n",
    "    jitter = np.random.normal(0, jitter_factor, data.shape)\n",
    "    return data + jitter\n",
    "\n",
    "def augment_data(X, y, noise_factor=0.01, warp_factor=0.2, jitter_factor=0.01):\n",
    "    augmented_X = []\n",
    "    augmented_y = []\n",
    "    \n",
    "    target_length = X.shape[1]\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        sample = X[i]\n",
    "        label = y[i]\n",
    "        \n",
    "        sample_with_noise = add_noise(sample, noise_factor)\n",
    "        warped_sample = time_warp(sample, target_length, warp_factor=warp_factor)\n",
    "        jittered_sample = jitter_data(sample, jitter_factor)\n",
    "        \n",
    "        augmented_X.extend([sample_with_noise, warped_sample, jittered_sample])\n",
    "        augmented_y.extend([label, label, label]) \n",
    "    \n",
    "    return np.array(augmented_X), np.array(augmented_y)\n",
    "\n",
    "\n",
    "augmented_X_train, augmented_y_train = augment_data(X_train, y_train)\n",
    "augmented_X_val, augmented_y_val = augment_data(X_val, y_val) \n",
    "\n",
    "np.save('augmented_X_train.npy', augmented_X_train)\n",
    "np.save('augmented_y_train.npy', augmented_y_train)\n",
    "np.save('augmented_X_val.npy', augmented_X_val)\n",
    "np.save('augmented_y_val.npy', augmented_y_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfb12b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation label counts: Counter({np.int64(0): 7, np.int64(3): 6, np.int64(2): 6, np.int64(1): 6})\n",
      "Test label counts: Counter({np.int64(2): 7, np.int64(3): 7, np.int64(0): 6, np.int64(1): 6})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(\"Validation label counts:\", Counter(y_val))\n",
    "print(\"Test label counts:\", Counter(y_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unimts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
